{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f41d654-372c-4e9e-9adb-d487c11f725e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.stats import uniform, randint\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import anndata as ad\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import xgboost as xgb\n",
    "import scanpy as sc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b64f076-f31d-4bbd-8a40-f253ab2c3d42",
   "metadata": {},
   "source": [
    "# Buscar os melhores par√¢metros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e7791f9-2905-4a68-b298-e061cc524b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/local.hcpa.ufrgs.br/tkruger/Install/conda/miniconda3/envs/ML/lib/python3.9/site-packages/anndata/_core/anndata.py:1897: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n",
      "/tmp/ipykernel_292326/254197543.py:31: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  adata.obs['broad_cell_type'] = adata.obs.index.map(adatab.obs['broad_cell_type'])\n"
     ]
    }
   ],
   "source": [
    "import pickle  # or use joblib\n",
    "\n",
    "adata=ad.read_h5ad('/home/local.hcpa.ufrgs.br/tkruger/V02_Glioblastoma_atlas/adatas/adata.h5ad')\n",
    "\n",
    "with open(\"final_xgb_model_20250504_025832.pkl\", \"rb\") as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "importance = model.feature_importances_\n",
    "feature_names = adata.var_names\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': importance\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "importance_df\n",
    "\n",
    "adatab=ad.read_h5ad('/home/local.hcpa.ufrgs.br/tkruger/V02_Glioblastoma_atlas/adatas/adata_5.h5ad')\n",
    "\n",
    "#Make row names unique\n",
    "adata.obs_names_make_unique()\n",
    "adatab.obs_names_make_unique()\n",
    "\n",
    "#Find intersections between adatas\n",
    "match = np.intersect1d(adata.obs_names, adatab.obs_names)\n",
    "\n",
    "#Keep adata matrix with obs that are in adatab\n",
    "adata = adata[match]\n",
    "\n",
    "#Map classes from adatab to adata\n",
    "adata.obs['broad_cell_type'] = adata.obs.index.map(adatab.obs['broad_cell_type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1e6580-039b-405f-90bf-bea8b95de065",
   "metadata": {},
   "source": [
    "# Remove 98,8% of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95fbd189-c0a2-485c-81c1-b777d61cbce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove = importance_df.tail(13010)['Feature']\n",
    "adata = adata[:, ~adata.var_names.isin(remove)]\n",
    "X = adata.X\n",
    "if not isinstance(X, np.ndarray):\n",
    "    X_array = X.toarray()\n",
    "else:\n",
    "    X_array = X\n",
    "y = adata.obs['broad_cell_type']\n",
    "df = pd.DataFrame({'label': y.values})\n",
    "np.save('main_X_50.npy', X_array)\n",
    "np.save('main_Y_50.npy', y)\n",
    "df.to_csv('main_df_50.csv')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train_dense = X_train.toarray()\n",
    "X_test_dense = X_test.toarray()\n",
    "row_sums_train = X_train_dense.sum(axis=1, keepdims=True)\n",
    "row_sums_test = X_test_dense.sum(axis=1, keepdims=True)\n",
    "X_train_normalized = X_train_dense / row_sums_train * 1000\n",
    "X_test_normalized = X_test_dense / row_sums_test * 1000\n",
    "X_train_log1p = np.log1p(X_train_normalized)\n",
    "X_test_log1p = np.log1p(X_test_normalized)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_log1p)\n",
    "X_test_scaled = scaler.fit_transform(X_test_log1p)\n",
    "np.save('feature_reduction/01_X_train.npy',X_train_scaled)\n",
    "np.save('feature_reduction/01_y_train.npy',y_train)\n",
    "np.save('feature_reduction/01_X_test.npy',X_test_scaled)\n",
    "np.save('feature_reduction/01_y_test.npy',y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896efdff-0f3b-4e20-a9e5-3338de7f1369",
   "metadata": {},
   "source": [
    "# Search for best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ca99e2-1a08-43f7-b9a0-7cbfd5db1460",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.stats import uniform, randint\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#Load train data\n",
    "train_data_subset = np.load('feature_reduction/01_X_train.npy')\n",
    "train_labels_subset = np.load('feature_reduction/01_y_train.npy', allow_pickle=True)\n",
    "\n",
    "#Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels_subset)\n",
    "\n",
    "#Define model\n",
    "model = XGBClassifier(use_label_encoder=False, eval_metric='logloss',n_jobs=1)\n",
    "\n",
    "# Define the parameter distributions\n",
    "param_distributions = {\n",
    "    'n_estimators': randint(100, 1000),\n",
    "    'max_depth': randint(3, 10),\n",
    "    'learning_rate': uniform(0.01, 0.3),\n",
    "    'subsample':uniform(0.5,1)\n",
    "    'colsample_bytree': uniform(0.5, 1),\n",
    "    'gamma': uniform(0, 5),\n",
    "    'min_child_weight': randint(1, 10),\n",
    "    'reg_alpha': uniform(0, 1),\n",
    "    'reg_lambda': uniform(0, 1)\n",
    "}\n",
    "\n",
    "# Random search\n",
    "random_search = RandomizedSearchCV(\n",
    "    model,\n",
    "    param_distributions,\n",
    "    n_iter=50,\n",
    "    cv=3,\n",
    "    random_state=42,\n",
    "    n_jobs=1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "random_search.fit(train_data_subset, train_labels_encoded)\n",
    "\n",
    "joblib.dump(random_search.best_estimator_, 'reduced_best_xgb_model.pkl')\n",
    "\n",
    "import json\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = random_search.best_params_\n",
    "\n",
    "# Save them to a JSON file\n",
    "with open('reduced_best_xgb_params.json', 'w') as f:\n",
    "    json.dump(best_params, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441484d5-8a84-4ef8-a8c3-d0543f32250a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035a589d-1152-4e3f-8203-f6dc6806d0a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1155a3-4e45-497d-a2e7-f85981ff5910",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
