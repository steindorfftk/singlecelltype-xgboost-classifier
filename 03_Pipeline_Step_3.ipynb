{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f41d654-372c-4e9e-9adb-d487c11f725e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.stats import uniform, randint\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import anndata as ad\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import xgboost as xgb\n",
    "import scanpy as sc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b64f076-f31d-4bbd-8a40-f253ab2c3d42",
   "metadata": {},
   "source": [
    "# 01 - Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7791f9-2905-4a68-b298-e061cc524b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle  # or use joblib\n",
    "\n",
    "adata=ad.read_h5ad('/home/local.hcpa.ufrgs.br/tkruger/V02_Glioblastoma_atlas/adatas/adata.h5ad')\n",
    "\n",
    "with open(\"final_xgb_model_20250504_025832.pkl\", \"rb\") as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "importance = model.feature_importances_\n",
    "feature_names = adata.var_names\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': importance\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "importance_df\n",
    "\n",
    "adatab=ad.read_h5ad('/home/local.hcpa.ufrgs.br/tkruger/V02_Glioblastoma_atlas/adatas/adata_5.h5ad')\n",
    "\n",
    "#Make row names unique\n",
    "adata.obs_names_make_unique()\n",
    "adatab.obs_names_make_unique()\n",
    "\n",
    "#Find intersections between adatas\n",
    "match = np.intersect1d(adata.obs_names, adatab.obs_names)\n",
    "\n",
    "#Keep adata matrix with obs that are in adatab\n",
    "adata = adata[match]\n",
    "\n",
    "#Map classes from adatab to adata\n",
    "adata.obs['broad_cell_type'] = adata.obs.index.map(adatab.obs['broad_cell_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab621a38-75a4-421d-98eb-ebacb2efe353",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a73e97c-e0a3-489b-9787-581b2a443833",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obsm[\"X_umap\"] = adatab.obsm[\"X_umap\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e19622-cd67-4fac-95d2-ecae7d192173",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(adatab, color='NPC2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23b908e-ac75-497f-88c2-73a9ff0d6f16",
   "metadata": {},
   "source": [
    "# 02 - Remove half of the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5b94d8-49c7-4b99-bfd9-648d6c6a61be",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove = importance_df.tail(6556)['Feature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f89bf0-c9ee-4072-b0ac-13adf09149d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2309b3-d2d6-412c-9510-0a8ba0294b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = adata[:, ~adata.var_names.isin(remove)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d79b86-3771-4488-9dcb-33dc0c64fd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4356500-5d3d-49c7-a316-06c7aea3a493",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa67661-8afd-4924-8175-e6e262326359",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract adata matrix\n",
    "X = adata.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c593ee-928f-491c-b686-f0fa378b1def",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not isinstance(X, np.ndarray):\n",
    "    X_array = X.toarray()\n",
    "else:\n",
    "    X_array = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c2fa75-43c6-47ae-b0b4-f392c1b9504e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract classes\n",
    "y = adata.obs['broad_cell_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cd763f-0db7-4785-b655-e766878de3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'label': y.values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78781d48-4728-4ee5-ad6b-672301d69dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save matrices and labels of train and test\n",
    "np.save('main_X_50.npy', X_array)\n",
    "np.save('main_Y_50.npy', y)\n",
    "df.to_csv('main_df_50.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e41298-0dfd-40fe-83cf-abdd22fc092d",
   "metadata": {},
   "source": [
    "# 03 - Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007d86a3-8c8c-4305-9e3d-dadaeb5b1321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best params:\n",
    "best_learning_rate = 0.22959818254342154\n",
    "best_max_depth = 7\n",
    "best_n_estimators = 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f7a440-73a9-49b7-ba0c-6b6debd569f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define model\n",
    "model = XGBClassifier(\n",
    "    learning_rate=best_learning_rate,\n",
    "    max_depth=best_max_depth,\n",
    "    n_estimators=best_n_estimators,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss',\n",
    "    n_jobs=1,\n",
    "    verbosity=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14361d4-74b8-457d-b6a0-4c55e47c2e1d",
   "metadata": {},
   "source": [
    "# 04 - Data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17454f4b-e2e2-4e64-98ec-36c649158df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divide dataset into train and test keeping proportions\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f97286-9c01-4016-8eee-fef64cb8d38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert matrices to dense\n",
    "X_train_dense = X_train.toarray()\n",
    "X_test_dense = X_test.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8d6edf-a9e2-457c-afe7-cd078241fb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get rows sums\n",
    "row_sums_train = X_train_dense.sum(axis=1, keepdims=True)\n",
    "row_sums_test = X_test_dense.sum(axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab702d6-7ff9-4879-8fb7-8c147d48e560",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize both matrices using row sums and scaling to 1000k counts\n",
    "X_train_normalized = X_train_dense / row_sums_train * 1000\n",
    "X_test_normalized = X_test_dense / row_sums_test * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289298ab-75b6-4803-ab36-77ee3dbbf60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply log1p to normalized counts\n",
    "X_train_log1p = np.log1p(X_train_normalized)\n",
    "X_test_log1p = np.log1p(X_test_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80ef544-cc1a-41b8-b8a1-ad29d916f082",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply scaler for mean = 0\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_log1p)\n",
    "X_test_scaled = scaler.fit_transform(X_test_log1p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bb6151-cdd4-42c0-bce1-b1d3a51b041d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save tuning subset\n",
    "np.save('feature_reduction/01_X_train.npy',X_train_scaled)\n",
    "np.save('feature_reduction/01_y_train.npy',y_train)\n",
    "np.save('feature_reduction/01_X_test.npy',X_test_scaled)\n",
    "np.save('feature_reduction/01_y_test.npy',y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f73e17b-77ba-4277-81ca-22673c329219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916c6c90-0410-4f06-858e-b8e49475a744",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = adata.X\n",
    "if not isinstance(X, np.ndarray):\n",
    "    X_array = X.toarray()\n",
    "else:\n",
    "    X_array = X\n",
    "y = adata.obs['broad_cell_type']\n",
    "df = pd.DataFrame({'label': y.values})\n",
    "np.save('main_X_50.npy', X_array)\n",
    "np.save('main_Y_50.npy', y)\n",
    "df.to_csv('main_df_50.csv')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train_dense = X_train.toarray()\n",
    "X_test_dense = X_test.toarray()\n",
    "row_sums_train = X_train_dense.sum(axis=1, keepdims=True)\n",
    "row_sums_test = X_test_dense.sum(axis=1, keepdims=True)\n",
    "X_train_normalized = X_train_dense / row_sums_train * 1000\n",
    "X_test_normalized = X_test_dense / row_sums_test * 1000\n",
    "X_train_log1p = np.log1p(X_train_normalized)\n",
    "X_test_log1p = np.log1p(X_test_normalized)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_log1p)\n",
    "X_test_scaled = scaler.fit_transform(X_test_log1p)\n",
    "np.save('feature_reduction/01_X_train.npy',X_train_scaled)\n",
    "np.save('feature_reduction/01_y_train.npy',y_train)\n",
    "np.save('feature_reduction/01_X_test.npy',X_test_scaled)\n",
    "np.save('feature_reduction/01_y_test.npy',y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde350a8-413b-4bc4-80c5-5cad54db1736",
   "metadata": {},
   "source": [
    "# Remove 50% of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07db6471-f783-419e-bb4a-14fd2a264486",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove = importance_df.tail(6556)['Feature']\n",
    "adata = adata[:, ~adata.var_names.isin(remove)]\n",
    "X = adata.X\n",
    "if not isinstance(X, np.ndarray):\n",
    "    X_array = X.toarray()\n",
    "else:\n",
    "    X_array = X\n",
    "y = adata.obs['broad_cell_type']\n",
    "df = pd.DataFrame({'label': y.values})\n",
    "np.save('main_X_50.npy', X_array)\n",
    "np.save('main_Y_50.npy', y)\n",
    "df.to_csv('main_df_50.csv')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train_dense = X_train.toarray()\n",
    "X_test_dense = X_test.toarray()\n",
    "row_sums_train = X_train_dense.sum(axis=1, keepdims=True)\n",
    "row_sums_test = X_test_dense.sum(axis=1, keepdims=True)\n",
    "X_train_normalized = X_train_dense / row_sums_train * 1000\n",
    "X_test_normalized = X_test_dense / row_sums_test * 1000\n",
    "X_train_log1p = np.log1p(X_train_normalized)\n",
    "X_test_log1p = np.log1p(X_test_normalized)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_log1p)\n",
    "X_test_scaled = scaler.fit_transform(X_test_log1p)\n",
    "np.save('feature_reduction/01_X_train.npy',X_train_scaled)\n",
    "np.save('feature_reduction/01_y_train.npy',y_train)\n",
    "np.save('feature_reduction/01_X_test.npy',X_test_scaled)\n",
    "np.save('feature_reduction/01_y_test.npy',y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acbe90b-80ad-4777-a9b7-df8a16123f46",
   "metadata": {},
   "source": [
    "# 05 - Remove 75% of the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66daabfd-fb7d-443b-ac11-ebb25c7d4114",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove = importance_df.tail(9834)['Feature']\n",
    "adata = adata[:, ~adata.var_names.isin(remove)]\n",
    "X = adata.X\n",
    "if not isinstance(X, np.ndarray):\n",
    "    X_array = X.toarray()\n",
    "else:\n",
    "    X_array = X\n",
    "y = adata.obs['broad_cell_type']\n",
    "df = pd.DataFrame({'label': y.values})\n",
    "np.save('main_X_50.npy', X_array)\n",
    "np.save('main_Y_50.npy', y)\n",
    "df.to_csv('main_df_50.csv')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train_dense = X_train.toarray()\n",
    "X_test_dense = X_test.toarray()\n",
    "row_sums_train = X_train_dense.sum(axis=1, keepdims=True)\n",
    "row_sums_test = X_test_dense.sum(axis=1, keepdims=True)\n",
    "X_train_normalized = X_train_dense / row_sums_train * 1000\n",
    "X_test_normalized = X_test_dense / row_sums_test * 1000\n",
    "X_train_log1p = np.log1p(X_train_normalized)\n",
    "X_test_log1p = np.log1p(X_test_normalized)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_log1p)\n",
    "X_test_scaled = scaler.fit_transform(X_test_log1p)\n",
    "np.save('feature_reduction/01_X_train.npy',X_train_scaled)\n",
    "np.save('feature_reduction/01_y_train.npy',y_train)\n",
    "np.save('feature_reduction/01_X_test.npy',X_test_scaled)\n",
    "np.save('feature_reduction/01_y_test.npy',y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63760df1-4f4f-4f2c-a7bf-9e73a6fb81d6",
   "metadata": {},
   "source": [
    "# Remove 82,5% of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b6e07a-cf7e-4730-a559-fde145eef4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove = importance_df.tail(11473)['Feature']\n",
    "adata = adata[:, ~adata.var_names.isin(remove)]\n",
    "X = adata.X\n",
    "if not isinstance(X, np.ndarray):\n",
    "    X_array = X.toarray()\n",
    "else:\n",
    "    X_array = X\n",
    "y = adata.obs['broad_cell_type']\n",
    "df = pd.DataFrame({'label': y.values})\n",
    "np.save('main_X_50.npy', X_array)\n",
    "np.save('main_Y_50.npy', y)\n",
    "df.to_csv('main_df_50.csv')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train_dense = X_train.toarray()\n",
    "X_test_dense = X_test.toarray()\n",
    "row_sums_train = X_train_dense.sum(axis=1, keepdims=True)\n",
    "row_sums_test = X_test_dense.sum(axis=1, keepdims=True)\n",
    "X_train_normalized = X_train_dense / row_sums_train * 1000\n",
    "X_test_normalized = X_test_dense / row_sums_test * 1000\n",
    "X_train_log1p = np.log1p(X_train_normalized)\n",
    "X_test_log1p = np.log1p(X_test_normalized)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_log1p)\n",
    "X_test_scaled = scaler.fit_transform(X_test_log1p)\n",
    "np.save('feature_reduction/01_X_train.npy',X_train_scaled)\n",
    "np.save('feature_reduction/01_y_train.npy',y_train)\n",
    "np.save('feature_reduction/01_X_test.npy',X_test_scaled)\n",
    "np.save('feature_reduction/01_y_test.npy',y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3efac87-821e-4903-8116-066bf1806c38",
   "metadata": {},
   "source": [
    "# Remove 93.75 of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45689fc0-a8d0-427f-b1e1-278a0157eab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove = importance_df.tail(12292)['Feature']\n",
    "adata = adata[:, ~adata.var_names.isin(remove)]\n",
    "X = adata.X\n",
    "if not isinstance(X, np.ndarray):\n",
    "    X_array = X.toarray()\n",
    "else:\n",
    "    X_array = X\n",
    "y = adata.obs['broad_cell_type']\n",
    "df = pd.DataFrame({'label': y.values})\n",
    "np.save('main_X_50.npy', X_array)\n",
    "np.save('main_Y_50.npy', y)\n",
    "df.to_csv('main_df_50.csv')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train_dense = X_train.toarray()\n",
    "X_test_dense = X_test.toarray()\n",
    "row_sums_train = X_train_dense.sum(axis=1, keepdims=True)\n",
    "row_sums_test = X_test_dense.sum(axis=1, keepdims=True)\n",
    "X_train_normalized = X_train_dense / row_sums_train * 1000\n",
    "X_test_normalized = X_test_dense / row_sums_test * 1000\n",
    "X_train_log1p = np.log1p(X_train_normalized)\n",
    "X_test_log1p = np.log1p(X_test_normalized)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_log1p)\n",
    "X_test_scaled = scaler.fit_transform(X_test_log1p)\n",
    "np.save('feature_reduction/01_X_train.npy',X_train_scaled)\n",
    "np.save('feature_reduction/01_y_train.npy',y_train)\n",
    "np.save('feature_reduction/01_X_test.npy',X_test_scaled)\n",
    "np.save('feature_reduction/01_y_test.npy',y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cda55b5-0f3a-49ee-9905-0499a6a7debe",
   "metadata": {},
   "source": [
    "# Remove 96.8% of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95eaa55-7469-4e74-a304-d17b1ad2c57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove = importance_df.tail(12702)['Feature']\n",
    "adata = adata[:, ~adata.var_names.isin(remove)]\n",
    "X = adata.X\n",
    "if not isinstance(X, np.ndarray):\n",
    "    X_array = X.toarray()\n",
    "else:\n",
    "    X_array = X\n",
    "y = adata.obs['broad_cell_type']\n",
    "df = pd.DataFrame({'label': y.values})\n",
    "np.save('main_X_50.npy', X_array)\n",
    "np.save('main_Y_50.npy', y)\n",
    "df.to_csv('main_df_50.csv')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train_dense = X_train.toarray()\n",
    "X_test_dense = X_test.toarray()\n",
    "row_sums_train = X_train_dense.sum(axis=1, keepdims=True)\n",
    "row_sums_test = X_test_dense.sum(axis=1, keepdims=True)\n",
    "X_train_normalized = X_train_dense / row_sums_train * 1000\n",
    "X_test_normalized = X_test_dense / row_sums_test * 1000\n",
    "X_train_log1p = np.log1p(X_train_normalized)\n",
    "X_test_log1p = np.log1p(X_test_normalized)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_log1p)\n",
    "X_test_scaled = scaler.fit_transform(X_test_log1p)\n",
    "np.save('feature_reduction/01_X_train.npy',X_train_scaled)\n",
    "np.save('feature_reduction/01_y_train.npy',y_train)\n",
    "np.save('feature_reduction/01_X_test.npy',X_test_scaled)\n",
    "np.save('feature_reduction/01_y_test.npy',y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ae9b29-26a2-40b1-81d3-4449c4b64c14",
   "metadata": {},
   "source": [
    "# Remove 98.4% of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41847a9-bb4a-47e3-9cdc-6fe5768793a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove = importance_df.tail(12907)['Feature']\n",
    "adata = adata[:, ~adata.var_names.isin(remove)]\n",
    "X = adata.X\n",
    "if not isinstance(X, np.ndarray):\n",
    "    X_array = X.toarray()\n",
    "else:\n",
    "    X_array = X\n",
    "y = adata.obs['broad_cell_type']\n",
    "df = pd.DataFrame({'label': y.values})\n",
    "np.save('main_X_50.npy', X_array)\n",
    "np.save('main_Y_50.npy', y)\n",
    "df.to_csv('main_df_50.csv')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train_dense = X_train.toarray()\n",
    "X_test_dense = X_test.toarray()\n",
    "row_sums_train = X_train_dense.sum(axis=1, keepdims=True)\n",
    "row_sums_test = X_test_dense.sum(axis=1, keepdims=True)\n",
    "X_train_normalized = X_train_dense / row_sums_train * 1000\n",
    "X_test_normalized = X_test_dense / row_sums_test * 1000\n",
    "X_train_log1p = np.log1p(X_train_normalized)\n",
    "X_test_log1p = np.log1p(X_test_normalized)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_log1p)\n",
    "X_test_scaled = scaler.fit_transform(X_test_log1p)\n",
    "np.save('feature_reduction/01_X_train.npy',X_train_scaled)\n",
    "np.save('feature_reduction/01_y_train.npy',y_train)\n",
    "np.save('feature_reduction/01_X_test.npy',X_test_scaled)\n",
    "np.save('feature_reduction/01_y_test.npy',y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1e6580-039b-405f-90bf-bea8b95de065",
   "metadata": {},
   "source": [
    "# Remove 98,8% of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fbd189-c0a2-485c-81c1-b777d61cbce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove = importance_df.tail(13010)['Feature']\n",
    "adata = adata[:, ~adata.var_names.isin(remove)]\n",
    "X = adata.X\n",
    "if not isinstance(X, np.ndarray):\n",
    "    X_array = X.toarray()\n",
    "else:\n",
    "    X_array = X\n",
    "y = adata.obs['broad_cell_type']\n",
    "df = pd.DataFrame({'label': y.values})\n",
    "np.save('main_X_50.npy', X_array)\n",
    "np.save('main_Y_50.npy', y)\n",
    "df.to_csv('main_df_50.csv')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train_dense = X_train.toarray()\n",
    "X_test_dense = X_test.toarray()\n",
    "row_sums_train = X_train_dense.sum(axis=1, keepdims=True)\n",
    "row_sums_test = X_test_dense.sum(axis=1, keepdims=True)\n",
    "X_train_normalized = X_train_dense / row_sums_train * 1000\n",
    "X_test_normalized = X_test_dense / row_sums_test * 1000\n",
    "X_train_log1p = np.log1p(X_train_normalized)\n",
    "X_test_log1p = np.log1p(X_test_normalized)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_log1p)\n",
    "X_test_scaled = scaler.fit_transform(X_test_log1p)\n",
    "np.save('feature_reduction/01_X_train.npy',X_train_scaled)\n",
    "np.save('feature_reduction/01_y_train.npy',y_train)\n",
    "np.save('feature_reduction/01_X_test.npy',X_test_scaled)\n",
    "np.save('feature_reduction/01_y_test.npy',y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b822a81-796d-46bc-ab48-234321ca4938",
   "metadata": {},
   "source": [
    "# Remove 99.6% of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571dcf8b-9030-4818-8237-c64399d0560c",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove = importance_df.tail(13061)['Feature']\n",
    "adata = adata[:, ~adata.var_names.isin(remove)]\n",
    "X = adata.X\n",
    "if not isinstance(X, np.ndarray):\n",
    "    X_array = X.toarray()\n",
    "else:\n",
    "    X_array = X\n",
    "y = adata.obs['broad_cell_type']\n",
    "df = pd.DataFrame({'label': y.values})\n",
    "np.save('main_X_50.npy', X_array)\n",
    "np.save('main_Y_50.npy', y)\n",
    "df.to_csv('main_df_50.csv')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train_dense = X_train.toarray()\n",
    "X_test_dense = X_test.toarray()\n",
    "row_sums_train = X_train_dense.sum(axis=1, keepdims=True)\n",
    "row_sums_test = X_test_dense.sum(axis=1, keepdims=True)\n",
    "X_train_normalized = X_train_dense / row_sums_train * 1000\n",
    "X_test_normalized = X_test_dense / row_sums_test * 1000\n",
    "X_train_log1p = np.log1p(X_train_normalized)\n",
    "X_test_log1p = np.log1p(X_test_normalized)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_log1p)\n",
    "X_test_scaled = scaler.fit_transform(X_test_log1p)\n",
    "np.save('feature_reduction/01_X_train.npy',X_train_scaled)\n",
    "np.save('feature_reduction/01_y_train.npy',y_train)\n",
    "np.save('feature_reduction/01_X_test.npy',X_test_scaled)\n",
    "np.save('feature_reduction/01_y_test.npy',y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc78935-ef7b-4672-a8ca-35b6fbff464c",
   "metadata": {},
   "source": [
    "# Remove 99.8% of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44febf3-38fc-4c91-908c-43acb56a89ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove = importance_df.tail(13087)['Feature']\n",
    "adata = adata[:, ~adata.var_names.isin(remove)]\n",
    "X = adata.X\n",
    "if not isinstance(X, np.ndarray):\n",
    "    X_array = X.toarray()\n",
    "else:\n",
    "    X_array = X\n",
    "y = adata.obs['broad_cell_type']\n",
    "df = pd.DataFrame({'label': y.values})\n",
    "np.save('main_X_50.npy', X_array)\n",
    "np.save('main_Y_50.npy', y)\n",
    "df.to_csv('main_df_50.csv')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train_dense = X_train.toarray()\n",
    "X_test_dense = X_test.toarray()\n",
    "row_sums_train = X_train_dense.sum(axis=1, keepdims=True)\n",
    "row_sums_test = X_test_dense.sum(axis=1, keepdims=True)\n",
    "X_train_normalized = X_train_dense / row_sums_train * 1000\n",
    "X_test_normalized = X_test_dense / row_sums_test * 1000\n",
    "X_train_log1p = np.log1p(X_train_normalized)\n",
    "X_test_log1p = np.log1p(X_test_normalized)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_log1p)\n",
    "X_test_scaled = scaler.fit_transform(X_test_log1p)\n",
    "np.save('feature_reduction/01_X_train.npy',X_train_scaled)\n",
    "np.save('feature_reduction/01_y_train.npy',y_train)\n",
    "np.save('feature_reduction/01_X_test.npy',X_test_scaled)\n",
    "np.save('feature_reduction/01_y_test.npy',y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb08ccc2-f5c4-4376-b404-64febae47d63",
   "metadata": {},
   "source": [
    "# Remove 99,9% of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c98db9-84e2-4948-bc79-2186e46bbf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove = importance_df.tail(13100)['Feature']\n",
    "adata = adata[:, ~adata.var_names.isin(remove)]\n",
    "X = adata.X\n",
    "if not isinstance(X, np.ndarray):\n",
    "    X_array = X.toarray()\n",
    "else:\n",
    "    X_array = X\n",
    "y = adata.obs['broad_cell_type']\n",
    "df = pd.DataFrame({'label': y.values})\n",
    "np.save('main_X_50.npy', X_array)\n",
    "np.save('main_Y_50.npy', y)\n",
    "df.to_csv('main_df_50.csv')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train_dense = X_train.toarray()\n",
    "X_test_dense = X_test.toarray()\n",
    "row_sums_train = X_train_dense.sum(axis=1, keepdims=True)\n",
    "row_sums_test = X_test_dense.sum(axis=1, keepdims=True)\n",
    "X_train_normalized = X_train_dense / row_sums_train * 1000\n",
    "X_test_normalized = X_test_dense / row_sums_test * 1000\n",
    "X_train_log1p = np.log1p(X_train_normalized)\n",
    "X_test_log1p = np.log1p(X_test_normalized)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_log1p)\n",
    "X_test_scaled = scaler.fit_transform(X_test_log1p)\n",
    "np.save('feature_reduction/01_X_train.npy',X_train_scaled)\n",
    "np.save('feature_reduction/01_y_train.npy',y_train)\n",
    "np.save('feature_reduction/01_X_test.npy',X_test_scaled)\n",
    "np.save('feature_reduction/01_y_test.npy',y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16a75b5-0b29-4b9c-8d92-bc6139261032",
   "metadata": {},
   "source": [
    "# Remove 99.95% of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccca8e37-ed19-4c86-9137-bfe2c6908c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove = importance_df.tail(13106)['Feature']\n",
    "adata = adata[:, ~adata.var_names.isin(remove)]\n",
    "X = adata.X\n",
    "if not isinstance(X, np.ndarray):\n",
    "    X_array = X.toarray()\n",
    "else:\n",
    "    X_array = X\n",
    "y = adata.obs['broad_cell_type']\n",
    "df = pd.DataFrame({'label': y.values})\n",
    "np.save('main_X_50.npy', X_array)\n",
    "np.save('main_Y_50.npy', y)\n",
    "df.to_csv('main_df_50.csv')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train_dense = X_train.toarray()\n",
    "X_test_dense = X_test.toarray()\n",
    "row_sums_train = X_train_dense.sum(axis=1, keepdims=True)\n",
    "row_sums_test = X_test_dense.sum(axis=1, keepdims=True)\n",
    "X_train_normalized = X_train_dense / row_sums_train * 1000\n",
    "X_test_normalized = X_test_dense / row_sums_test * 1000\n",
    "X_train_log1p = np.log1p(X_train_normalized)\n",
    "X_test_log1p = np.log1p(X_test_normalized)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_log1p)\n",
    "X_test_scaled = scaler.fit_transform(X_test_log1p)\n",
    "np.save('feature_reduction/01_X_train.npy',X_train_scaled)\n",
    "np.save('feature_reduction/01_y_train.npy',y_train)\n",
    "np.save('feature_reduction/01_X_test.npy',X_test_scaled)\n",
    "np.save('feature_reduction/01_y_test.npy',y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7d34fc-daa4-424e-8711-056f178fa15b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5312dbce-a144-4b4c-87c1-8e076a476039",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(adata.var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa8f682-2e06-4198-b58b-12cd42b0e62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(adatab, color='TMEM144') #Expressed by oligo in their differentiation from OPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410b4290-f52d-46ec-9a73-00e4a8337468",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(adatab, color='CKB') #Possível novo marcador de glioblastoma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2a5035-3a83-4c4f-a7c0-b36b9493326b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(adatab, color='CSF1R') #Marcador de macrófagos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2c15da-b17a-4bb0-a503-2807533919c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(adatab, color='CD34') #Marcador de células endoteliais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a7aeee-87e6-4a54-8833-34d8d00c0f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(adatab, color='QDPR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1961e2d-7edc-41cf-b200-f877d247cc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(adatab, color='IL2RG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f3c676-4f21-4d1b-ac4b-e7e1ace676e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(adatab, color='CNDP1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0de2b86-d3b5-40c1-ab3f-34e3f2a55c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(adatab, color='SRGN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd780d26-2aeb-41ae-844f-f49a847d6ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(adatab, color='CD96')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a24b91a-c3cd-4cd4-911c-3e73becd6d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.var.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27427359-e621-444e-963c-d86b936ae246",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ca99e2-1a08-43f7-b9a0-7cbfd5db1460",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb93ef1-fcf2-4979-a290-f121813bd508",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441484d5-8a84-4ef8-a8c3-d0543f32250a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035a589d-1152-4e3f-8203-f6dc6806d0a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1155a3-4e45-497d-a2e7-f85981ff5910",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
